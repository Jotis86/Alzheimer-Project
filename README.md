# ğŸ§  Alzheimer AI: Detection and Support ğŸŒ¸

![Image](./Images/image_2.jpeg)

![GitHub commit activity](https://img.shields.io/github/commit-activity/m/Jotis86/Alzheimer-Project)
![GitHub forks](https://img.shields.io/github/forks/Jotis86/Alzheimer-Project?style=social)
![GitHub issues](https://img.shields.io/github/issues/Jotis86/Alzheimer-Project)
![GitHub pull requests](https://img.shields.io/github/issues-pr/Jotis86/Alzheimer-Project)
![GitHub license](https://img.shields.io/github/license/Jotis86/Alzheimer-Project)
![GitHub stars](https://img.shields.io/github/stars/Jotis86/Alzheimer-Project?style=social)
![GitHub contributors](https://img.shields.io/github/contributors/Jotis86/Alzheimer-Project)

## Objectives ğŸ¯

The objective of this project is to develop a comprehensive solution for the early detection and management of Alzheimer's disease. This includes:

1. **Machine Learning Model**: Predict the probability of Alzheimer's in patients using clinical data.
2. **Deep Learning Model**: Detect the presence of Alzheimer's disease in MRI brain scan images.
3. **Interactive Application**: Create an interactive Streamlit application to visualize the results and facilitate medical decision-making.
4. **Chat Bot Assistant**: Integrate a chat bot to assist users with questions related to Alzheimer's disease.
5. **Alexa Skill**: Develop an Alexa skill to assist both users and caregivers in their daily routines.

By combining these components, we aim to provide a robust tool for the early detection and management of Alzheimer's disease, ultimately improving patient outcomes and supporting caregivers.


## Tools Used ğŸ› ï¸
- **ğŸ Python**: Main programming language.
- **ğŸ“Š Pandas**: Data manipulation and analysis.
- **ğŸ”¢ NumPy**: Numerical operations.
- **ğŸ¤– Scikit-learn**: Machine learning models.
- **ğŸ§  TensorFlow**: Deep learning models.
- **ğŸ“ˆ Matplotlib and Seaborn**: Data visualization.
- **ğŸŒ Streamlit**: Web application development.
- **ğŸ“Š PowerBI**: Advanced data visualization.
- **ğŸ“‹ Trello**: Project management.
- **ğŸ—£ï¸ Amazon Alexa**: Voice assistant skill development.
- **ğŸ¤– Cohere**: Natural language processing for the chat bot.
- **ğŸ“‚ Joblib**: Model serialization and deserialization.
- **ğŸ”§ OpenCV**: Image processing.
- **ğŸ–¼ï¸ Pillow**: Image manipulation.
- **ğŸ”‘ Python-dotenv**: Environment variable management.


## Development Process ğŸ—ï¸
1. **ğŸ“¥ Data Collection**: 
   - Obtaining clinical and imaging data from patients.
   - Sources include medical records, MRI scans, and patient surveys.

2. **ğŸ§¹ Data Preprocessing**: 
   - Cleaning and transforming the data to ensure quality and consistency.
   - Handling missing values, normalizing data, and encoding categorical variables.

3. **ğŸ” Exploratory Data Analysis (EDA)**: 
   - Identifying patterns and relationships in the data.
   - Visualizing data distributions, correlations, and trends using tools like Matplotlib and Seaborn.

4. **ğŸ¤– Model Development**: 
   - Training and evaluating machine learning models using Scikit-learn.
   - Developing deep learning models using TensorFlow for image classification.
   - Hyperparameter tuning and model optimization to improve performance.

5. **ğŸš€ Application Deployment**: 
   - Creating an interactive web application with Streamlit to visualize results and facilitate medical decision-making.
   - Integrating machine learning and deep learning models into the application.
   - Implementing a chat bot using Cohere for natural language processing.

6. **ğŸ“Š Data Visualization**: 
   - Using PowerBI for advanced visualizations and dashboards.
   - Creating interactive reports to provide insights and support decision-making.

7. **ğŸ—£ï¸ Voice Assistant Integration**: 
   - Developing an Alexa skill to assist both users and caregivers in their daily routines.
   - Training the skill to provide information and support related to Alzheimer's disease.

8. **ğŸ”„ Continuous Improvement**: 
   - Collecting feedback from users and stakeholders to improve the application.
   - Iteratively refining models and visualizations based on new data and insights.